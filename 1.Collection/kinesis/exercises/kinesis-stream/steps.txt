1- Create S3 Bucket
    -Select a name for Order Logs

2- Create Kinesis Data Stream
    -Name: CadabraOrders (Or anyone)
    -Number of shards: 1
    -Stream capacity:
        -Write 1Mb per second
        -1000 records per seconds
        -Read 2 MB per second

3 - Create new key pair for ec2 instance

4 - Create Ec2 Instance
    -Amazon Linux AMI
    -t2-micro
    -Select created key pair

5 - Login into Ec2 Instance
    - Run "sudo yum install -y aws-kinesis-agent"
    - Run "wget http://media.sundog-soft.com/AWSBigData/LogGenerator.zip"
    - Run "unzip LogGenerator.zip"
    - Run "chmod a+x LogGenerator.py"
    - Run "sudo mkdir /var/log/cadabra"
    - Run "cd /etc/aws-kinesis/"
    - Run "sudo nano agent.json"
        -copy the flows from /Materials/OrderHistory/agent.nano.txt 
            above the filePattern and deliveryStream from Firehose
    - Run "sudo service aws-kinesis-agent restart" //Or start if is the first time
    - Run "cd ~"
    - Run "sudo ./LogGenerator.py"
    - Run "tail -f /var/log/aws-kinesis-agent/aws-kinesis-agent.log"